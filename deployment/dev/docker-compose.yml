services:
  scapper:
    build:
      context: ../../source
      dockerfile: Dockerfile
    container_name: ${APP_NAME}
    environment:
      - DJANGO_SETTINGS_MODULE=vpscrapproject.settings
      - ALLOWED_HOSTS=${APP_ALLOWED_HOSTS}
      - APP_HOST_NAME=${APP_NAME}
      - APP_PORT=${APP_PORT}
      - DB_ENGINE=${APP_DB_ENGINE}
      - DB_HOST=${APP_DB_NAME}
      - DB_DB=${POSTGRES_DB}
      - DB_USER=${POSTGRES_USER}
      - DB_PASSWORD=${POSTGRES_PASSWORD}
      - DB_PORT=${POSTGRES_PORT}
    entrypoint: [ "/bin/sh", "-c" ]
    command:
      - |
        python3 manage.py makemigrations
        python3 manage.py migrate
        python3 manage.py runserver 0.0.0.0:${APP_PORT}
    healthcheck:
      test: curl --fail http://0.0.0.0:${APP_PORT}/ || exit 1
      interval: 40s
      timeout: 30s
      retries: 3
      start_period: 60s
    depends_on:
      scrapper-db:
        condition: service_healthy
    networks:
      - network_back

  scrapper-db:
    image: postgres:13
    container_name: ${APP_DB_NAME}
    environment:
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=${POSTGRES_DB}
    healthcheck:
      test: pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}
      interval: 10s
      timeout: 3s
      retries: 3
    volumes:
      - ./scrapper-db/:/var/lib/postgresql/data/
    networks:
      - network_back

  nginx:
    build:
      context: ../../nginx/local
      dockerfile: Dockerfile
    environment:
      - APP_HOST_NAME=${APP_NAME}
      - APP_PORT=${APP_PORT}
    ports:
      - "8001:80"
    networks:
      - network_front
      - network_back
    depends_on:
      - scrapper
  celery_worker:
    build: scraper_api
    networks:
      - network_back
    container_name: celery_worker
    hostname: celery_worker
    depends_on:
      web_db:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy
    environment:
      - TZ=${TZ}
    command: ['celery', '-A', 'app.scraper', 'worker', '-l', 'info']


  celery_beat:
    build: scraper_api
    networks:
      - network_back
    container_name: celery_beat
    hostname: celery_beat
    depends_on:
      web_db:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy
    environment:
      - TZ=${TZ}
    command: [ 'celery', '-A', 'app.scraper', 'beat', '-l', 'info']

  redis:
    image: redis:7.0.9-alpine
    environment:
      - ALLOW_EMPTY_PASSWORD=yes
    networks:
      - network_back

  rabbitmq:
    image: rabbitmq:3-management-alpine
    container_name: rabbitmq
    hostname: rabbitmq
    ports:
      - "5672:5672"
      - "15672:15672"
    networks:
      - network_back
    volumes:
      - ~/.docker-conf/rabbitmq/data/:/var/lib/rabbitmq/
      - ~/.docker-conf/rabbitmq/log/:/var/log/rabbitmq/

    healthcheck:
      test: rabbitmq-diagnostics check_port_connectivity
      interval: 1s
      timeout: 3s
      retries: 30
    environment:
      - TZ=${TZ}


networks:
  network_front:
    driver: bridge
  network_back:
    driver: bridge
    internal: true
